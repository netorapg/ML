import pandas as pd
import numpy as np

def fazer_melt_csv(arquivo_entrada='../all.csv', arquivo_saida='all_melted.csv'):

    print(" FAZENDO MELT DO CSV")
    print("="*50)
    
    # Carregar dados
    print(f" Carregando {arquivo_entrada}...")
    df = pd.read_csv(arquivo_entrada)
    print(f"   Formato original: {df.shape[0]} linhas √ó {df.shape[1]} colunas")
    
    # Identificar colunas de valores (v1-v20)
    value_cols = [f'v{i}' for i in range(1, 21)]
    id_cols = ['dataset', 'classifier', 'metric', 'author']
    
    print(f"   Colunas de ID: {id_cols}")
    print(f"   Colunas de valores: {len(value_cols)} colunas (v1-v20)")
    
    # Fazer o melt
    print(" Aplicando melt...")
    df_melted = pd.melt(
        df, 
        id_vars=id_cols,
        value_vars=value_cols,
        var_name='experimento',
        value_name='valor'
    )
    
    # Converter valores para num√©rico (importante!)
    print(" Convertendo valores para num√©rico...")
    df_melted['valor'] = pd.to_numeric(df_melted['valor'], errors='coerce')
    
    # Remover linhas com valores inv√°lidos
    linhas_antes = len(df_melted)
    df_melted = df_melted.dropna(subset=['valor'])
    linhas_depois = len(df_melted)
    
    if linhas_antes != linhas_depois:
        print(f"     Removidas {linhas_antes - linhas_depois} linhas com valores inv√°lidos")
    
    df_melted['experimento_num'] = df_melted['experimento'].str.extract(r'(\d+)').astype(int)
    
    df_melted = df_melted[['dataset', 'classifier', 'metric', 'experimento', 'experimento_num', 'valor', 'author']]
    
    df_melted = df_melted.sort_values(['dataset', 'classifier', 'metric', 'experimento_num'])
    
    print(f"   Formato final: {df_melted.shape[0]} linhas √ó {df_melted.shape[1]} colunas")
    
    print(f" Salvando {arquivo_saida}...")
    df_melted.to_csv(arquivo_saida, index=False)
    
    # Mostrar estat√≠sticas
    print("\n ESTAT√çSTICAS DO MELT:")
    print(f"   Datasets √∫nicos: {df_melted['dataset'].nunique()}")
    print(f"   Classificadores √∫nicos: {df_melted['classifier'].nunique()}")
    print(f"   M√©tricas √∫nicas: {df_melted['metric'].nunique()}")
    print(f"   Autores √∫nicos: {df_melted['author'].nunique()}")
    print(f"   Experimentos por combina√ß√£o: {df_melted['experimento'].nunique()}")
    
    # Mostrar alguns exemplos
    print("\n PRIMEIRAS 10 LINHAS DO RESULTADO:")
    print(df_melted.head(10).to_string(index=False))
    
    # Verificar valores faltantes
    valores_nan = df_melted['valor'].isna().sum()
    if valores_nan > 0:
        print(f"\n  ATEN√á√ÉO: {valores_nan} valores faltantes encontrados!")
        # Mostrar quais combina√ß√µes t√™m valores faltantes
        nan_data = df_melted[df_melted['valor'].isna()]
        print("   Combina√ß√µes com valores faltantes:")
        for _, row in nan_data.iterrows():
            print(f"     {row['dataset']} | {row['classifier']} | {row['metric']} | {row['experimento']} | {row['author']}")
    else:
        print("\n Nenhum valor faltante encontrado!")
    
    print(f"\nüéØ MELT CONCLU√çDO!")
    print(f"   Arquivo salvo: {arquivo_saida}")
    
    return df_melted

def criar_filtro_naive_bayes_f1(df_melted):
    """
    Cria um CSV filtrado apenas com Naive Bayes + F1 Score
    """
    print(f"\nüìã CRIANDO FILTRO: NAIVE BAYES + F1 SCORE")
    print("="*50)
    
    # Filtrar apenas Naive Bayes + F1 Score
    filtro = (df_melted['classifier'] == 'naive_bayes') & (df_melted['metric'] == 'f1_score')
    df_nb_f1 = df_melted[filtro].copy()
    
    print(f"   üìä Dados filtrados: {len(df_nb_f1)} registros")
    print(f"   üìà Datasets √∫nicos: {df_nb_f1['dataset'].nunique()}")
    print(f"   üë• Autores √∫nicos: {df_nb_f1['author'].nunique()}")
    
    # Salvar CSV filtrado
    output_file = 'naive_bayes_f1_score.csv'
    df_nb_f1.to_csv(output_file, index=False)
    
    print(f"\nüìä ESTAT√çSTICAS DO FILTRO:")
    print(f"   Datasets: {sorted(df_nb_f1['dataset'].unique())}")
    print(f"   Total de experimentos: {len(df_nb_f1)}")
    print(f"   M√©dia geral F1-Score: {df_nb_f1['valor'].mean():.4f}")
    print(f"   Desvio padr√£o: {df_nb_f1['valor'].std():.4f}")
    print(f"   Range: {df_nb_f1['valor'].min():.4f} - {df_nb_f1['valor'].max():.4f}")
    
    # Estat√≠sticas por dataset
    print(f"\nüìà ESTAT√çSTICAS POR DATASET:")
    stats_por_dataset = df_nb_f1.groupby('dataset')['valor'].agg(['count', 'mean', 'std', 'min', 'max'])
    stats_por_dataset.columns = ['Experimentos', 'M√©dia', 'Desvio', 'M√≠nimo', 'M√°ximo']
    print(stats_por_dataset.round(4))
    
    # Mostrar algumas linhas de exemplo
    print(f"\nüîç PRIMEIRAS 10 LINHAS DO FILTRO:")
    colunas_exibir = ['dataset', 'experimento', 'valor', 'author']
    print(df_nb_f1[colunas_exibir].head(10).to_string(index=False))
    
    print(f"\n‚úÖ FILTRO SALVO: {output_file}")
    
    return df_nb_f1

def exemplo_analise(df_melted):
    """
    Exemplo de an√°lise com os dados em formato long
    """
    print("\n EXEMPLO DE AN√ÅLISE COM DADOS MELTED:")
    print("="*50)
    
    # Filtrar apenas Naive Bayes + F1 Score
    nb_f1 = df_melted[
        (df_melted['classifier'] == 'naive_bayes') & 
        (df_melted['metric'] == 'f1_score')
    ].copy()
    
    if len(nb_f1) > 0:
        print(f" Naive Bayes + F1 Score: {len(nb_f1)} registros")
        
        # Verificar se todos os valores s√£o num√©ricos
        if nb_f1['valor'].dtype in ['object', 'string']:
            print(" Convertendo valores para num√©rico...")
            nb_f1['valor'] = pd.to_numeric(nb_f1['valor'], errors='coerce')
            nb_f1 = nb_f1.dropna(subset=['valor'])
            print(f" Ap√≥s convers√£o: {len(nb_f1)} registros v√°lidos")
        
        if len(nb_f1) > 0:
            # Estat√≠sticas por dataset
            stats_por_dataset = nb_f1.groupby('dataset')['valor'].agg(['count', 'mean', 'std', 'min', 'max'])
            print("\n Estat√≠sticas por Dataset:")
            print(stats_por_dataset.round(4))
            
            # Melhor e pior dataset
            melhor_dataset = stats_por_dataset['mean'].idxmax()
            pior_dataset = stats_por_dataset['mean'].idxmin()
            
            print(f"\n Melhor dataset: {melhor_dataset} (m√©dia: {stats_por_dataset.loc[melhor_dataset, 'mean']:.4f})")
            print(f" Pior dataset: {pior_dataset} (m√©dia: {stats_por_dataset.loc[pior_dataset, 'mean']:.4f})")
        else:
            print(" Nenhum valor num√©rico v√°lido encontrado")
        
    else:
        print(" Nenhum dado de Naive Bayes + F1 Score encontrado")

if __name__ == "__main__":
    # Fazer o melt
    df_melted = fazer_melt_csv()
    
    # Exemplo de an√°lise
    exemplo_analise(df_melted)
    
    # Criar CSV filtrado para Naive Bayes + F1 Score
    criar_filtro_naive_bayes_f1(df_melted)
    
    print("\n SCRIPT CONCLU√çDO!")
    print("   Agora voc√™ pode usar 'all_melted.csv' para an√°lises mais f√°ceis!")
    print("   Criamos tamb√©m 'naive_bayes_f1_filtered.csv' para an√°lise espec√≠fica do Naive Bayes!")