{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d8287f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import SVC  # Importando SVM\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn import metrics\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9ddf1b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape do dataset: (8124, 23)\n",
      "\n",
      "Primeiras 5 linhas:\n",
      "  class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
      "0     p         x           s         n       t    p               f   \n",
      "1     e         x           s         y       t    a               f   \n",
      "2     e         b           s         w       t    l               f   \n",
      "3     p         x           y         w       t    p               f   \n",
      "4     e         x           s         g       f    n               f   \n",
      "\n",
      "  gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
      "0            c         n          k  ...                        s   \n",
      "1            c         b          k  ...                        s   \n",
      "2            c         b          n  ...                        s   \n",
      "3            c         n          n  ...                        s   \n",
      "4            w         b          k  ...                        s   \n",
      "\n",
      "  stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
      "0                      w                      w         p          w   \n",
      "1                      w                      w         p          w   \n",
      "2                      w                      w         p          w   \n",
      "3                      w                      w         p          w   \n",
      "4                      w                      w         p          w   \n",
      "\n",
      "  ring-number ring-type spore-print-color population habitat  \n",
      "0           o         p                 k          s       u  \n",
      "1           o         p                 n          n       g  \n",
      "2           o         p                 n          n       m  \n",
      "3           o         p                 k          s       u  \n",
      "4           o         e                 n          a       g  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "column_names = [\n",
    "    'class', 'cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor',\n",
    "    'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color',\n",
    "    'stalk-shape', 'stalk-root', 'stalk-surface-above-ring', \n",
    "    'stalk-surface-below-ring', 'stalk-color-above-ring', \n",
    "    'stalk-color-below-ring', 'veil-type', 'veil-color',\n",
    "    'ring-number', 'ring-type', 'spore-print-color', \n",
    "    'population', 'habitat'\n",
    "]\n",
    "\n",
    "df = pd.read_csv('agaricus-lepiota.data', names=column_names)\n",
    "\n",
    "print(f\"Shape do dataset: {df.shape}\")\n",
    "print(f\"\\nPrimeiras 5 linhas:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5c1a1f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VERIFICAÇÃO DE DADOS FALTANTES ===\n",
      "Total de valores ausentes por coluna:\n",
      "class                       0\n",
      "cap-shape                   0\n",
      "cap-surface                 0\n",
      "cap-color                   0\n",
      "bruises                     0\n",
      "odor                        0\n",
      "gill-attachment             0\n",
      "gill-spacing                0\n",
      "gill-size                   0\n",
      "gill-color                  0\n",
      "stalk-shape                 0\n",
      "stalk-root                  0\n",
      "stalk-surface-above-ring    0\n",
      "stalk-surface-below-ring    0\n",
      "stalk-color-above-ring      0\n",
      "stalk-color-below-ring      0\n",
      "veil-type                   0\n",
      "veil-color                  0\n",
      "ring-number                 0\n",
      "ring-type                   0\n",
      "spore-print-color           0\n",
      "population                  0\n",
      "habitat                     0\n",
      "dtype: int64\n",
      "\n",
      "Verificando valores '?' que representam dados faltantes:\n",
      "class                          0\n",
      "cap-shape                      0\n",
      "cap-surface                    0\n",
      "cap-color                      0\n",
      "bruises                        0\n",
      "odor                           0\n",
      "gill-attachment                0\n",
      "gill-spacing                   0\n",
      "gill-size                      0\n",
      "gill-color                     0\n",
      "stalk-shape                    0\n",
      "stalk-root                  2480\n",
      "stalk-surface-above-ring       0\n",
      "stalk-surface-below-ring       0\n",
      "stalk-color-above-ring         0\n",
      "stalk-color-below-ring         0\n",
      "veil-type                      0\n",
      "veil-color                     0\n",
      "ring-number                    0\n",
      "ring-type                      0\n",
      "spore-print-color              0\n",
      "population                     0\n",
      "habitat                        0\n",
      "dtype: int64\n",
      "\n",
      "Total de linhas com dados faltantes:\n",
      "2480 linhas contém '?'\n",
      "\n",
      "Valores únicos em 'stalk-root':\n",
      "stalk-root\n",
      "b    3776\n",
      "?    2480\n",
      "e    1120\n",
      "c     556\n",
      "r     192\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"=== VERIFICAÇÃO DE DADOS FALTANTES ===\")\n",
    "print(f\"Total de valores ausentes por coluna:\")\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "print(f\"\\nVerificando valores '?' que representam dados faltantes:\")\n",
    "question_marks = (df == '?').sum()\n",
    "print(question_marks)\n",
    "\n",
    "print(f\"\\nTotal de linhas com dados faltantes:\")\n",
    "rows_with_missing = df[df == '?'].any(axis=1).sum()\n",
    "print(f\"{rows_with_missing} linhas contém '?'\")\n",
    "\n",
    "print(f\"\\nValores únicos em 'stalk-root':\")\n",
    "print(df['stalk-root'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9b43abf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== REMOÇÃO DE DADOS FALTANTES ===\n",
      "Dataset original: (8124, 23)\n",
      "Dataset após remoção: (5644, 23)\n",
      "Linhas removidas: 2480\n",
      "\n",
      "Verificação final - valores '?' restantes:\n",
      "class                       0\n",
      "cap-shape                   0\n",
      "cap-surface                 0\n",
      "cap-color                   0\n",
      "bruises                     0\n",
      "odor                        0\n",
      "gill-attachment             0\n",
      "gill-spacing                0\n",
      "gill-size                   0\n",
      "gill-color                  0\n",
      "stalk-shape                 0\n",
      "stalk-root                  0\n",
      "stalk-surface-above-ring    0\n",
      "stalk-surface-below-ring    0\n",
      "stalk-color-above-ring      0\n",
      "stalk-color-below-ring      0\n",
      "veil-type                   0\n",
      "veil-color                  0\n",
      "ring-number                 0\n",
      "ring-type                   0\n",
      "spore-print-color           0\n",
      "population                  0\n",
      "habitat                     0\n",
      "dtype: int64\n",
      "Dataset após remoção: (5644, 23)\n",
      "Linhas removidas: 2480\n",
      "\n",
      "Verificação final - valores '?' restantes:\n",
      "class                       0\n",
      "cap-shape                   0\n",
      "cap-surface                 0\n",
      "cap-color                   0\n",
      "bruises                     0\n",
      "odor                        0\n",
      "gill-attachment             0\n",
      "gill-spacing                0\n",
      "gill-size                   0\n",
      "gill-color                  0\n",
      "stalk-shape                 0\n",
      "stalk-root                  0\n",
      "stalk-surface-above-ring    0\n",
      "stalk-surface-below-ring    0\n",
      "stalk-color-above-ring      0\n",
      "stalk-color-below-ring      0\n",
      "veil-type                   0\n",
      "veil-color                  0\n",
      "ring-number                 0\n",
      "ring-type                   0\n",
      "spore-print-color           0\n",
      "population                  0\n",
      "habitat                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"=== REMOÇÃO DE DADOS FALTANTES ===\")\n",
    "print(f\"Dataset original: {df.shape}\")\n",
    "\n",
    "df_clean = df[~(df == '?').any(axis=1)]\n",
    "\n",
    "print(f\"Dataset após remoção: {df_clean.shape}\")\n",
    "print(f\"Linhas removidas: {df.shape[0] - df_clean.shape[0]}\")\n",
    "\n",
    "print(f\"\\nVerificação final - valores '?' restantes:\")\n",
    "print((df_clean == '?').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "97659637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PREPARAÇÃO DOS DADOS ===\n",
      "Classes no target:\n",
      "class\n",
      "e    3488\n",
      "p    2156\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape dos dados finais:\n",
      "X: (5644, 22)\n",
      "y: (5644,)\n",
      "Mapeamento do target: {'e': np.int64(0), 'p': np.int64(1)}\n"
     ]
    }
   ],
   "source": [
    "print(\"=== PREPARAÇÃO DOS DADOS ===\")\n",
    "X = df_clean.drop('class', axis=1)\n",
    "y = df_clean['class']\n",
    "\n",
    "print(f\"Classes no target:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "label_encoders = {}\n",
    "x_encoded = X.copy()\n",
    "\n",
    "for column in X.columns:\n",
    "    le = LabelEncoder()\n",
    "    x_encoded[column] = le.fit_transform(X[column])\n",
    "    label_encoders[column] = le\n",
    "    \n",
    "le_target = LabelEncoder()\n",
    "y_encoded = le_target.fit_transform(y)\n",
    "\n",
    "print(f\"\\nShape dos dados finais:\")\n",
    "print(f\"X: {x_encoded.shape}\")\n",
    "print(f\"y: {y_encoded.shape}\")\n",
    "print(f\"Mapeamento do target: {dict(zip(le_target.classes_, le_target.transform(le_target.classes_)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3ae30244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SHUFFLE DOS DADOS ===\n",
      "Dados embaralhados com sucesso!\n",
      "Primeiros 5 indices após shuffle: [3215 1743 1709 3211 1098]\n"
     ]
    }
   ],
   "source": [
    "print(\"=== SHUFFLE DOS DADOS ===\")\n",
    "\n",
    "x_array = x_encoded.values\n",
    "y_array = y_encoded\n",
    "\n",
    "indices = np.arange(len(x_array))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "x_shuffled = x_array[indices]\n",
    "y_shuffled = y_array[indices]\n",
    "\n",
    "print(f\"Dados embaralhados com sucesso!\")\n",
    "print(f\"Primeiros 5 indices após shuffle: {indices[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "acc2748a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DIVISÃO TREINO/TESTE ===\n",
      "Tamanho do conjunto de treino: (4515, 22)\n",
      "Tamanho do conjunto de teste: (1129, 22)\n",
      "Distribuição de classes no treino: [2790 1725]\n",
      "Distribuição das classes no teste: [698 431]\n"
     ]
    }
   ],
   "source": [
    "print(\"=== DIVISÃO TREINO/TESTE ===\")\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_shuffled, y_shuffled,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_shuffled\n",
    ")\n",
    "\n",
    "print(f\"Tamanho do conjunto de treino: {x_train.shape}\")\n",
    "print(f\"Tamanho do conjunto de teste: {x_test.shape}\")\n",
    "print(f\"Distribuição de classes no treino: {np.bincount(y_train)}\")\n",
    "print(f\"Distribuição das classes no teste: {np.bincount(y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "87e665da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TREINAMENTO DO PERCEPTRON ===\n",
      "Modelo treinado com sucesso!\n",
      "Número de iterações realizadas: 44\n",
      "Modelo treinado com sucesso!\n",
      "Número de iterações realizadas: 44\n"
     ]
    }
   ],
   "source": [
    "print(\"=== TREINAMENTO DO PERCEPTRON ===\")\n",
    "\n",
    "perceptron = Perceptron(random_state=42, max_iter=1000)\n",
    "perceptron.fit(x_train, y_train)\n",
    "\n",
    "print(f\"Modelo treinado com sucesso!\")\n",
    "print(f\"Número de iterações realizadas: {perceptron.n_iter_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "67b136af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AVALIAÇÃO DO MODELO ===\n",
      "Acurácia no treino: 0.8560\n",
      "Acurácia no teste: 0.8441\n",
      "\n",
      "Relatório de classificação (teste):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Comestível       0.99      0.75      0.86       698\n",
      "    Venenoso       0.71      0.99      0.83       431\n",
      "\n",
      "    accuracy                           0.84      1129\n",
      "   macro avg       0.85      0.87      0.84      1129\n",
      "weighted avg       0.89      0.84      0.85      1129\n",
      "\n",
      "\n",
      "Matriz de confusão (teste):\n",
      "[[525 173]\n",
      " [  3 428]]\n",
      "Verdadeiros Positivos (Venenosos corretamente identificados): 428\n",
      "Falsos Negativos (Venenosos classificados como comestíveis): 3\n"
     ]
    }
   ],
   "source": [
    "print(\"=== AVALIAÇÃO DO MODELO ===\")\n",
    "y_pred_train = perceptron.predict(x_train)\n",
    "y_pred_test = perceptron.predict(x_test)\n",
    "\n",
    "print(f\"Acurácia no treino: {accuracy_score(y_train, y_pred_train):.4f}\")\n",
    "print(f\"Acurácia no teste: {accuracy_score(y_test, y_pred_test):.4f}\")\n",
    "\n",
    "print(f\"\\nRelatório de classificação (teste):\")\n",
    "target_names = ['Comestível', 'Venenoso']\n",
    "print(classification_report(y_test, y_pred_test, target_names=target_names))\n",
    "\n",
    "print(f\"\\nMatriz de confusão (teste):\")\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "print(cm)\n",
    "print(f\"Verdadeiros Positivos (Venenosos corretamente identificados): {cm[1,1]}\")\n",
    "print(f\"Falsos Negativos (Venenosos classificados como comestíveis): {cm[1,0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a2801c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TREINAMENTO DO SVM ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo SVM treinado com sucesso!\n",
      "Kernel usado: rbf\n",
      "Número de vetores de suporte: [241 240]\n",
      "Total de vetores de suporte: 481\n"
     ]
    }
   ],
   "source": [
    "print(\"=== TREINAMENTO DO SVM ===\")\n",
    "\n",
    "# Criar e treinar o modelo SVM\n",
    "svm = SVC(random_state=42, kernel='rbf')  # kernel RBF é uma boa opção padrão\n",
    "svm.fit(x_train, y_train)\n",
    "\n",
    "print(f\"Modelo SVM treinado com sucesso!\")\n",
    "print(f\"Kernel usado: {svm.kernel}\")\n",
    "print(f\"Número de vetores de suporte: {svm.n_support_}\")\n",
    "print(f\"Total de vetores de suporte: {svm.support_vectors_.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "968a1dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AVALIAÇÃO DO SVM ===\n",
      "Acurácia SVM no treino: 0.9976\n",
      "Acurácia SVM no teste: 1.0000\n",
      "\n",
      "Relatório de classificação SVM (teste):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Comestível       1.00      1.00      1.00       698\n",
      "    Venenoso       1.00      1.00      1.00       431\n",
      "\n",
      "    accuracy                           1.00      1129\n",
      "   macro avg       1.00      1.00      1.00      1129\n",
      "weighted avg       1.00      1.00      1.00      1129\n",
      "\n",
      "\n",
      "Matriz de confusão SVM (teste):\n",
      "[[698   0]\n",
      " [  0 431]]\n",
      "Verdadeiros Positivos (Venenosos corretamente identificados): 431\n",
      "Falsos Negativos (Venenosos classificados como comestíveis): 0\n",
      "Acurácia SVM no treino: 0.9976\n",
      "Acurácia SVM no teste: 1.0000\n",
      "\n",
      "Relatório de classificação SVM (teste):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Comestível       1.00      1.00      1.00       698\n",
      "    Venenoso       1.00      1.00      1.00       431\n",
      "\n",
      "    accuracy                           1.00      1129\n",
      "   macro avg       1.00      1.00      1.00      1129\n",
      "weighted avg       1.00      1.00      1.00      1129\n",
      "\n",
      "\n",
      "Matriz de confusão SVM (teste):\n",
      "[[698   0]\n",
      " [  0 431]]\n",
      "Verdadeiros Positivos (Venenosos corretamente identificados): 431\n",
      "Falsos Negativos (Venenosos classificados como comestíveis): 0\n"
     ]
    }
   ],
   "source": [
    "print(\"=== AVALIAÇÃO DO SVM ===\")\n",
    "\n",
    "# Predições do SVM\n",
    "y_pred_train_svm = svm.predict(x_train)\n",
    "y_pred_test_svm = svm.predict(x_test)\n",
    "\n",
    "print(f\"Acurácia SVM no treino: {accuracy_score(y_train, y_pred_train_svm):.4f}\")\n",
    "print(f\"Acurácia SVM no teste: {accuracy_score(y_test, y_pred_test_svm):.4f}\")\n",
    "\n",
    "print(f\"\\nRelatório de classificação SVM (teste):\")\n",
    "target_names = ['Comestível', 'Venenoso']\n",
    "print(classification_report(y_test, y_pred_test_svm, target_names=target_names))\n",
    "\n",
    "print(f\"\\nMatriz de confusão SVM (teste):\")\n",
    "cm_svm = confusion_matrix(y_test, y_pred_test_svm)\n",
    "print(cm_svm)\n",
    "print(f\"Verdadeiros Positivos (Venenosos corretamente identificados): {cm_svm[1,1]}\")\n",
    "print(f\"Falsos Negativos (Venenosos classificados como comestíveis): {cm_svm[1,0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c2eecbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPARAÇÃO PERCEPTRON vs SVM ===\n",
      "Modelo       Treino   Teste   \n",
      "============ ======== ========\n",
      "Perceptron   0.8560   0.8441  \n",
      "SVM          0.9976   1.0000  \n",
      "\n",
      "Diferença de performance:\n",
      "Treino: SVM supera Perceptron em 0.1415\n",
      "Teste: SVM supera Perceptron em 0.1559\n"
     ]
    }
   ],
   "source": [
    "print(\"=== COMPARAÇÃO PERCEPTRON vs SVM ===\")\n",
    "\n",
    "# Comparar as acurácias\n",
    "acc_perceptron_train = accuracy_score(y_train, y_pred_train)\n",
    "acc_perceptron_test = accuracy_score(y_test, y_pred_test)\n",
    "acc_svm_train = accuracy_score(y_train, y_pred_train_svm)\n",
    "acc_svm_test = accuracy_score(y_test, y_pred_test_svm)\n",
    "\n",
    "print(f\"{'Modelo':<12} {'Treino':<8} {'Teste':<8}\")\n",
    "print(f\"{'='*12} {'='*8} {'='*8}\")\n",
    "print(f\"{'Perceptron':<12} {acc_perceptron_train:<8.4f} {acc_perceptron_test:<8.4f}\")\n",
    "print(f\"{'SVM':<12} {acc_svm_train:<8.4f} {acc_svm_test:<8.4f}\")\n",
    "\n",
    "print(f\"\\nDiferença de performance:\")\n",
    "diff_train = acc_svm_train - acc_perceptron_train\n",
    "diff_test = acc_svm_test - acc_perceptron_test\n",
    "print(f\"Treino: SVM {'supera' if diff_train > 0 else 'fica atrás do'} Perceptron em {abs(diff_train):.4f}\")\n",
    "print(f\"Teste: SVM {'supera' if diff_test > 0 else 'fica atrás do'} Perceptron em {abs(diff_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5e537063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TESTANDO DIFERENTES KERNELS DO SVM ===\n",
      "\n",
      "Testando kernel: linear\n",
      "Acurácia com kernel linear: 0.9814\n",
      "\n",
      "Testando kernel: poly\n",
      "Acurácia com kernel poly: 1.0000\n",
      "\n",
      "Testando kernel: rbf\n",
      "Acurácia com kernel linear: 0.9814\n",
      "\n",
      "Testando kernel: poly\n",
      "Acurácia com kernel poly: 1.0000\n",
      "\n",
      "Testando kernel: rbf\n",
      "Acurácia com kernel rbf: 1.0000\n",
      "\n",
      "Testando kernel: sigmoid\n",
      "Acurácia com kernel rbf: 1.0000\n",
      "\n",
      "Testando kernel: sigmoid\n",
      "Acurácia com kernel sigmoid: 0.7857\n",
      "\n",
      "=== RESUMO DOS KERNELS ===\n",
      "Kernel     Acurácia  \n",
      "========== ==========\n",
      "poly       1.0000     ⭐\n",
      "rbf        1.0000    \n",
      "linear     0.9814    \n",
      "sigmoid    0.7857    \n",
      "\n",
      "Melhor kernel: poly com acurácia de 1.0000\n",
      "Acurácia com kernel sigmoid: 0.7857\n",
      "\n",
      "=== RESUMO DOS KERNELS ===\n",
      "Kernel     Acurácia  \n",
      "========== ==========\n",
      "poly       1.0000     ⭐\n",
      "rbf        1.0000    \n",
      "linear     0.9814    \n",
      "sigmoid    0.7857    \n",
      "\n",
      "Melhor kernel: poly com acurácia de 1.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"=== TESTANDO DIFERENTES KERNELS DO SVM ===\")\n",
    "\n",
    "# Testar diferentes kernels\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "results = {}\n",
    "\n",
    "for kernel in kernels:\n",
    "    print(f\"\\nTestando kernel: {kernel}\")\n",
    "    \n",
    "    # Criar e treinar SVM com kernel específico\n",
    "    svm_kernel = SVC(random_state=42, kernel=kernel)\n",
    "    svm_kernel.fit(x_train, y_train)\n",
    "    \n",
    "    # Fazer predições\n",
    "    y_pred_kernel = svm_kernel.predict(x_test)\n",
    "    acc_kernel = accuracy_score(y_test, y_pred_kernel)\n",
    "    \n",
    "    results[kernel] = acc_kernel\n",
    "    print(f\"Acurácia com kernel {kernel}: {acc_kernel:.4f}\")\n",
    "\n",
    "print(f\"\\n=== RESUMO DOS KERNELS ===\")\n",
    "best_kernel = max(results, key=results.get)\n",
    "print(f\"{'Kernel':<10} {'Acurácia':<10}\")\n",
    "print(f\"{'='*10} {'='*10}\")\n",
    "for kernel, acc in sorted(results.items(), key=lambda x: x[1], reverse=True):\n",
    "    marker = \" ⭐\" if kernel == best_kernel else \"\"\n",
    "    print(f\"{kernel:<10} {acc:<10.4f}{marker}\")\n",
    "    \n",
    "print(f\"\\nMelhor kernel: {best_kernel} com acurácia de {results[best_kernel]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5c95d5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Fazendo F1-Score ===\n",
      "F1-Score Perceptron: 0.8295\n",
      "F1-Score SVM: 1.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Fazendo F1-Score ===\")\n",
    "\n",
    "f1_perceptron = metrics.f1_score(y_test, y_pred_test)\n",
    "f1_svm = metrics.f1_score(y_test, y_pred_test_svm)\n",
    "\n",
    "print(f\"F1-Score Perceptron: {f1_perceptron:.4f}\")\n",
    "print(f\"F1-Score SVM: {f1_svm:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
